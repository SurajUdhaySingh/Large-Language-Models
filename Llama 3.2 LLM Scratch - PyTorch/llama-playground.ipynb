{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f552f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877beb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06717c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hey, how are you doing? I'm doing pretty well, thanks for asking. How about you? What's new with you? I'm\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Hey, how are you doing?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fd614d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Generate an absurd news article. Here\\'s a possible one:\\n\\n**BREAKING: Alien Invasion of New York City, Scientists Stunned by \"Gigantic, Tentacled Monster\"**\\n\\nIn a shocking turn of events, the city of New York has been invaded by an extraterrestrial force, leaving scientists baffled and the general public in a state of utter confusion.\\n\\nEyewitnesses report that the alien entity, described as a \"gigantic, tentacled monster\" with an unknown number of limbs, descended upon the city in the early hours of the morning, sending shockwaves through the streets.\\n\\n\"I was just walking to work when I saw this...this thing,\" said Jane Doe, a local resident. \"It was huge, with these long, spindly arms and a face that looked like a cross between a squid and a giant octopus. I was terrified.\"\\n\\nAccording to sources, the alien entity is estimated to be around 100 feet in length, with a mass of approximately 10,000 tons. Its \"tentacles\" are said to be capable of stretching for miles, allowing it to grab and drag objects from the ground.\\n\\n\"It\\'s like nothing I\\'ve ever seen before,\" said Dr.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Generate an absurd news article.\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=248)\n",
    "tokenizer.batch_decode(generate_ids,\n",
    "                       skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61fe14fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
